{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayes_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook gives a rough guide on how to run a Bayesian Cross-Match with the included code. All matches are made to a Gaia DR2 subset, and assume the file has the headers found in the file \"\". A file with a different format will break the code.\n",
    "\n",
    "The first step in the process is to do the initial cross-match to the external catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external catalog that has already been pre-queried around all of the Gaia sources\n",
    "# this file MUST be sorted by RA\n",
    "external_file = 'PAN_STARRS_star_pm040mas_30as_radius_extrap_epoch_sorted.txt\n",
    "\n",
    "# chunk size for large file loading\n",
    "chunck_size = 4e6\n",
    "\n",
    "# number of rows in external file\n",
    "external_file_length = 203974312\n",
    "\n",
    "# column number for the external catalog ids\n",
    "id_col = [0]\n",
    "\n",
    "# column numbers for [ra, dec, epoch]\n",
    "# it is assumed that the epoch is in mjd\n",
    "ra_dec_epoch_cols = [1,2,5]\n",
    "\n",
    "# file name where to store initial best matches\n",
    "initial_best_save = 'PAN_STARRS_GAIADR2_star_pm040mas_best_matches.txt'\n",
    "\n",
    "# file where to store all matches within 15\"\n",
    "all_match_save = 'PAN_STARRS_GAIADR2_star_pm040mas_all_matches.txt'\n",
    "\n",
    "# column numbers of all magntiudes and magntidue errors (alternating)\n",
    "mag_cols = [6,7,8,9,10,11,12,13,14,15]\n",
    "\n",
    "# the file name of the Gaia sources the external catalog is being matched to\n",
    "match_file = 'GAIADR2_star_pm040mas.txt'\n",
    "\n",
    "best_epochs = bayes_match.cross_match(external_file, chunck_size, external_file_length, id_col,\n",
    "                                      ra_dec_epoch_cols, initial_best_save,\n",
    "                                      all_match_save, mag_cols, match_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, do the same for the displaced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# external catalog that has already been pre-queried around all of the Gaia sources\n",
    "# by displacing the search location by +/- 2 arcminutes\n",
    "# this file MUST be sorted by RA\n",
    "external_file = 'PAN_STARRS_star_pm040mas_dis_30as_radius_extrap_epoch_sorted.txt\n",
    "\n",
    "# chunk size for large file loading\n",
    "chunck_size = 4e6\n",
    "\n",
    "# number of rows in external file\n",
    "external_file_length = 203974312\n",
    "\n",
    "# column number for the external catalog ids\n",
    "id_col = [0]\n",
    "\n",
    "# column numbers for [ra, dec, epoch]\n",
    "# it is assumed that the epoch is in mjd\n",
    "ra_dec_epoch_cols = [1,2,5]\n",
    "\n",
    "# file name where to store initial best matches\n",
    "initial_best_save = 'PAN_STARRS_GAIADR2_star_pm040mas_dis_best_matches.txt'\n",
    "\n",
    "# file where to store all matches within 15\"\n",
    "all_match_save = 'PAN_STARRS_GAIADR2_star_pm040mas_dis_all_matches.txt'\n",
    "\n",
    "# column numbers of all magntiudes and magntidue errors (alternating)\n",
    "mag_cols = [6,7,8,9,10,11,12,13,14,15]\n",
    "\n",
    "# the file name of the Gaia sources the external catalog is being matched to\n",
    "match_file = 'GAIADR2_star_pm040mas.txt'\n",
    "\n",
    "bayes_match.cross_match_dis(external_file, chunck_size, external_file_length, id_col,\n",
    "                            ra_dec_epoch_cols, initial_best_save,\n",
    "                            all_match_save, mag_cols, match_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the above two steps can take a long time to run (on the order of a day or more) depending on the size of your catalogs and the machine you are using. You have been warned! (and stay tune for possible future optimizations to make this not the case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, reclculate the angular seperations to the mean epoch of the best matches and rank the matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mean_epoch = np.mean(best_epochs[(best_epochs > 1950.) & (best_epochs < 2050.)])\n",
    "\n",
    "path = ''\n",
    "# file where all matches stored\n",
    "file = 'PAN_STARRS_GAIADR2_star_pm040mas_all_matches.txt'\n",
    "# file where ranks are saved\n",
    "file_save = 'PAN_STARRS_GAIADR2_star_pm040mas_all_matches_ranks.txt'\n",
    "\n",
    "bayes_match.rank_match_check_dups(path, file,file_save, mean_epoch, flag=None, mag_cols=None)\n",
    "\n",
    "# file where all matches stored for displaced sample\n",
    "file = 'PAN_STARRS_GAIADR2_star_pm040mas_dis_all_matches.txt'\n",
    "# file where ranks are saved for displaced sample\n",
    "file_save = 'PAN_STARRS_GAIADR2_star_pm040mas_dis_all_matches_ranks.txt'\n",
    "\n",
    "bayes_match.rank_match_check_dups(path, file, file_save, mean_epoch, flag=None, mag_cols=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create files that contain all of the frequency distirbutions to begin finding our Bayesian probabilit distirbutions. As a note, this requires that a directory called \"Distribution_Files\" is in the current working directory.\n",
    "\n",
    "As a note, these distribtuions are divided by various cuts in Gaia G and Galactic latitude (b), as described in Medan, Lepine & Hartman (2021). These are hard coded into these functions, so if they do not suit your needs they will need to be changed within the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "file = 'PAN_STARRS_GAIADR2_star_pm040mas_all_matches.txt'\n",
    "file_rank = 'PAN_STARRS_GAIADR2_star_pm040mas_all_matches_ranks.txt'\n",
    "file_dis = 'PAN_STARRS_GAIADR2_star_pm040mas_dis_all_matches.txt'\n",
    "file_dis_rank = 'PAN_STARRS_GAIADR2_star_pm040mas_dis_all_matches_ranks.txt'\n",
    "name = 'PAN_STARRS'\n",
    "mag_cols = [15,17,19,21,23]\n",
    "# bins for frequency distirbution for angular seperation axis\n",
    "xbins = np.arange(0,20.2,0.2)\n",
    "# bins for frequency distirbution for mag difference axis\n",
    "ybins = np.arange(-30,30.2,0.2)\n",
    "\n",
    "\n",
    "bayes_match.fit_mag_ang_dists(path, file,file_rank, file_dis, file_dis_rank,\n",
    "                              name, mag_cols, xbins, ybins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to model the frequency distributions for the displaced sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_match.back_mod_2d_gauss('PAN_STARRS',['g','r','i','z','y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate the Bayesian cross-match probabilities for all stars in the external catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import percentile_filter\n",
    "\n",
    "all_file = '_GAIADR2_star_pm040mas_all_matches.txt'\n",
    "rank_file = '_GAIADR2_star_pm040mas_all_matches_ranks.txt'\n",
    "name = 'PAN_STARRS'\n",
    "mag_cols = [15,17,19,21,23]\n",
    "# filter to use for smoothing the true distributions\n",
    "smooth_filter = percentile_filter\n",
    "# params for the filtert\n",
    "filter_params = {'percentile':60,'size':5}\n",
    "\n",
    "bayes_match.calc_bayes_prob(name, smooth_filter,\n",
    "                            filter_params,\n",
    "                            mag_cols, all_file, rank_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step would be to create the files that only contain the most probable matches at a threshold of p>95%. Optionally, you can also create files that only contain the other possible matches in the field that are not deemed as the \"best\" match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file = '_GAIADR2_star_pm040mas_all_matches.txt'\n",
    "rank_file = '_GAIADR2_star_pm040mas_all_matches_ranks.txt'\n",
    "bayes_file = '_bayes_probs_per_mag_gaia_cut_b_cut.txt'\n",
    "name = 'PAN_STARRS'\n",
    "# whether or not you want to also create file for other possible matches\n",
    "make_rank_2 = True\n",
    "\n",
    "bayes_match.make_best_and_rank_2_sample(name, all_file, rank_file, bayes_file, make_rank_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note the structure of the resulting files so results can then be used as you like. This final section of the workflow will result in three main files for the best matches (and similar files for the other possible matches). These three files (for this example) are:\n",
    "\n",
    "**PAN_STARRS_GAIADR2_star_pm040mas_all_matches_bayes_matches_best_match.txt**\n",
    "\n",
    "With a table structure like (seperated over two lines cause its long):\n",
    "\n",
    "| Gaia ID | RA (Gaia) | Dec (Gaia) | plx (Gaia) | plx_err (Gaia) | pmra (Gaia) | pmdec (Gaia) | Gmag (Gaia) | ID (External) | RA (External) | Dec (External) | Epoch |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| ... | deg | deg | mas | mas| mas/yr | mas/yr | mag | ... | deg | deg | mjd |\n",
    "\n",
    "| ang_sep_RA_impact | ang_sep_Dec_impact | Epoch_Impact | mag1 (external) | mag1_err (External) | ... | magN (external) | magN_err (External)| line_num |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| arcseconds | arcseconds | Decimal Year | mag | mag | ... | mag | mag | ... |\n",
    "\n",
    "**PAN_STARRS_GAIADR2_star_pm040mas_all_matches_ranks_bayes_matches_best_match.txt**\n",
    "\n",
    "With a table structure like:\n",
    "\n",
    "| Rank | ang_sep_RA_mean | ang_sep_Dec_mean|\n",
    "| --- | --- | --- |\n",
    "| ... |  arcseconds | arcseconds |\n",
    "\n",
    "**PAN_STARRS_GAIADR2_star_pm040mas_all_matches_bayes_probs_per_mag_gaia_cut_b_cut_bayes_matches_best_match.txt**\n",
    "\n",
    "With a table structure like:\n",
    "\n",
    "| bayes_prob_mag1 | ... | bayes_prob_magN |\n",
    "| --- | --- | --- |\n",
    "| ... |  ... | ... |\n",
    "\n",
    "All three of these files have the same length and each row in a file matches the corresponding Gaia ID in the first file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
